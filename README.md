# OmniParser

**OmniParser** is a multimodal document understanding model developed by Microsoft. It combines icon detection and vision-language captioning to parse and extract structured information from visually-rich documents such as forms, tables, and charts. This repository contains code and instructions to set up and run OmniParser locally, including a Gradio-based user interface for demonstration.

---

## üîß System Requirements

Before getting started, ensure your system meets the following requirements:

- **Operating System**: Linux, macOS, or Windows (WSL2 recommended)  
- **Python Version**: 3.12 (required)  
- **Memory**: At least 8 GB RAM (16 GB+ recommended)  
- **Disk Space**: ~5 GB of free space  
- **GPU**: Recommended for faster inference (NVIDIA GPU with CUDA support)  

---

## üõ†Ô∏è Installation & Setup

Follow the steps below to install and run the OmniParser model:

```bash
# 1. Clone the Repository
git clone https://github.com/microsoft/OmniParser.git
cd OmniParser

# 2. Create and Activate Conda Environment
conda create -n "omni" python==3.12
conda activate omni

# 3. Install Required Python Packages
pip install -r requirements.txt

# 4. Log In to Hugging Face
huggingface-cli login
# If you don't have an account, create one at https://huggingface.co/join

# 5. Download Model Weights
for f in icon_detect/{train_args.yaml,model.pt,model.yaml} \
        icon_caption/{config.json,generation_config.json,model.safetensors}; do
  huggingface-cli download microsoft/OmniParser-v2.0 "$f" --local-dir weights
done

# 6. Organize Model Weights
mv weights/icon_caption weights/icon_caption_blip2  # or icon_caption_florence

#7. Launch the Application
python gradio_demo.py
